{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-IIEY_l98O_7"
   },
   "source": [
    "# Exercise Sheet 2 - MNIST Classification with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yl8FXR3s8PBB"
   },
   "source": [
    " * Deep Learning â€“ Winter term 2019/20\n",
    " * Instructor: Alexander Ecker\n",
    " * Tutor: Peter Chronz\n",
    " * Due date: Jan 6, 2020 at noon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eaoMWjbZdCLf"
   },
   "source": [
    "# IMPORTANT SUBMISSION INSTRUCTIONS\n",
    "\n",
    "- When you're done, download the notebook and rename it to \\<surname1\\>_\\<surname2\\>_\\<surname3\\>.ipynb\n",
    "- Only submit the ipynb file, no other file is required\n",
    "- Submit only once\n",
    "- The deadline is strict\n",
    "- You are required to present your solution in the tutorial; submission of the notebook alone is not sufficient\n",
    "\n",
    "Implementation\n",
    "- Only change code to replace placeholders. Leave the other code as is.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rwaaZtaJ8PBI"
   },
   "source": [
    "## Questions\n",
    "* **There are seven cells with questions throughout the notebook. Make sure to answer those questions in the empty cell below.**\n",
    "* In addition to the question cells there are code exercises marked in the code cells. Just fill in the placeholders, which are marked like so: `<PUT IN SOME CODE HERE>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ep2PNrTr1TKM"
   },
   "source": [
    "# PyTorch\n",
    "\n",
    "We will be using PyTorch as our framework throughout the rest of the term. Some of the basics are explained in this exercise and implemented for you already, but it is not meant to be a comprehensive tutorial for learning PyTorch. Please refer to the excellent online resources:\n",
    "\n",
    " - Documentation: https://pytorch.org/docs/\n",
    " - Tutorials: https://pytorch.org/tutorials/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RSaZHscD8PBK"
   },
   "source": [
    "## Setup/requirements (skip if using Colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F5XKteTu8PBN"
   },
   "source": [
    "If you're not using Colab, install the required libraries before running this notebook.\n",
    "* fastprogress for progress bars during training\n",
    "* matplotlib to plot loss\n",
    "* seaborn to plot the confusion matrix as a heatmap\n",
    "* pytorch and torchvision for most of the operations\n",
    "\n",
    "Choose the installation method based on your system. All tested with the Anaconda setup, but it should be fine via pip3 as well. Note that pip3 might simply be pip on your system.\n",
    "\n",
    "If you're missing any of the dependencies, you can uncomment the code below. Choose either the Anaconda version or the python version. You might need to install Anaconda first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o_TiepIM8PBP"
   },
   "source": [
    "### Anaconda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AGtT8Rfx8PBR"
   },
   "outputs": [],
   "source": [
    "#This code is not running like this!\n",
    "#I had to download the Anaconda Tool and insert it into the 'Anaconda Prompt', but without the !\n",
    "\n",
    "# !conda install -c fastai fastprogress\n",
    "# !conda install -c conda-forge matplotlib\n",
    "# !conda install -c anaconda seaborn\n",
    "# !conda install pytorch torchvision cudatoolkit=10.1 -c pytorch # with CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "43pXTPMg8PBV"
   },
   "source": [
    "### Pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jWWrHBu18PBX"
   },
   "outputs": [],
   "source": [
    "# !pip3 install fastprogress\n",
    "# !pip3 install matplotlib\n",
    "# !pip3 install seaborn\n",
    "# !pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lBX7G6nm8PBa"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xo4MVsQj8PBb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "\n",
    "import fastprogress\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wXfMlc3_8PBg"
   },
   "source": [
    "## System checks\n",
    "\n",
    "Perform some rudimentary system checks. Do we have a CUDA-capable device? Multiple? Is CuDNN active (huge speedups for some networks)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Lo5sRjw8PBi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True, 0)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available(), torch.backends.cudnn.is_available(), torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uSkGnMux8PBo"
   },
   "source": [
    "Choose your device for computation. CPU or one of your CUDA devices?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MSyb08pX8PBq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = True\n",
    "use_cuda = False if not use_cuda else torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if use_cuda else 'cpu')\n",
    "torch.cuda.get_device_name(device) if use_cuda else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aDCFFn-_8PBu"
   },
   "source": [
    "How many CPUs do we have? Use that as a guide to set the # of workers for multiprocessing in the data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a1CMBy4E8PBv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cpus = os.cpu_count()\n",
    "num_cpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nxa07_Af8PBz"
   },
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8hreJGgn8PB0"
   },
   "source": [
    "Set the data dir and download the MNIST dataset to that location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UaLiwZSu8PB2"
   },
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yO4Sw3Za8PB7"
   },
   "source": [
    "Get the data set. We will use a popular data set, which is already integrated with pytorch. However, it's quite easy to implement your own dataset.\n",
    "\n",
    "A data set is a subclass of ``DataSet`` (https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset). DataSet `implements` ``__len__`` and ``__get_item__``, which allow it to be used by a data loader.\n",
    "\n",
    "https://pytorch.org/docs/stable/torchvision/datasets.html#mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e5AFBM6d8PB9"
   },
   "outputs": [],
   "source": [
    "mnist_train = datasets.MNIST(data_dir, download=True, train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "niIMyM-98PCB"
   },
   "source": [
    "Create a data loader (https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) for our data set. Adjust the batch size, so that the batches (incl. the net) fit snuggly into memory. Generally, larger batch sizes are better. Adjust the number of workers; play around and notice the impact on your iteration speed. How fast is your memory access and your FS access (quad channel memory and NVMe SSDs are nice)?\n",
    "\n",
    "While the data set provides access to the raw data, the data loader provides higher level access to the data.\n",
    "For example, the data loader\n",
    "* packs data points into batches,\n",
    "* shuffles the data,\n",
    "* loads data in parallel, by managing workers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hiTR4evH8PCC"
   },
   "source": [
    "Review the data. It's always a good idea to have checkpoints to make sure that things work.\n",
    "Since DataSet implements ``__len__`` and ``__getitem__``, **we can access the data as if it were a list**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iyrRFEhK8PCC"
   },
   "outputs": [],
   "source": [
    "# <SELECT THE FIRST ELEMENT FROM THE DATA SET HERE. WHAT'S INSIDE?>\n",
    "x, y = mnist_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cpfzKDQd8PCF"
   },
   "source": [
    "We see that the dataset provides a tuple: (x, y). x is the image, y is the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_DYUndJR8PCF"
   },
   "source": [
    "Let's look at some random images (always a good idead if possible). \n",
    "Instead of rendering the image in code, just return the image to Jupyter, which will then recognize it as a PIL.Image and render automatically. \n",
    "Run this cell a couple of time to make sture that the labels are correct and to get a feeling for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 56 #we have to set i to a vaule, otherwise it is not initializised!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u2g1tWH-8PCG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABCklEQVR4nGNgGMwg5W0lhMFrIIQu1/L63ykGBgYGBo7N/+LQJR/8e2vAwMDAwMB1ESLJhCLdfIGBgYGBgU3i70M0jYYf7olAWGX/9qPJCT//XwFhiZ/9l48qx7bi/0d9CDP03z8VVMmQf/+cISyOE/928KLIMa/5dxfqt4p/3wxQNS76904Oypz77wqqXMnff5lQZsGff42oksf+rWFkYGBQyZ708++/SzAbWWDStzj92RNNOBkYGBh2fUbX+eXjv3///t3v+fNvJSuqHEPnn3///t3aEMHA8OtfBQM6kLQpl+JjYGDg/P1PEkMSBlL+HUKYyoQmGcnw5DdOST5kDrpk8/9rOK2kFgAAq61cvw3ICogAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x23A8CDF4AC8>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <CHOOSE A RANDOM ELEMENT FROM THE DATASET HERE. THEN RUN THE CELL MULTIPLE TIMES BY HAND.>\n",
    "i += 1\n",
    "x, y = mnist_train[i]\n",
    "print(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4uy4ryTX8PCI"
   },
   "source": [
    "How many data points are there in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8eBelVr68PCJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <OBTAIN AND PRINT OUT THE LENGHT OF THE DATA SET>\n",
    "len(mnist_train)\n",
    "\n",
    "#we have 60000 entries in our train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_3Brd-aj8PCN"
   },
   "source": [
    "## Pre-process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CDgCYCmU8PCO"
   },
   "source": [
    "We have seen above that the contents of the data set are of type ``[(PIL.Image.Image, Int)]``. However, pytorch (the core that is, not torchvision or torchtext) is only equipped to work on Tensor objects. So we need to transform ``PIL.Image.Image`` to ``torch.Tensor``. Torchvision takes care of that for us. ``transforms.ToTensor`` is a transformation operation that maps a ``PIL.Image.Image`` to a troch tensor.\n",
    "\n",
    "Furthermore, we will normalize the data to zero-mean and unit-variance. ``transforms.Normalize`` takes the mean and std-dev for each channel and rescales the data to zero-mean, unit-variance. https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.Normalize\n",
    "\n",
    "We can combine multiple transformations via ``transforms.Compose``.\n",
    "\n",
    "So let's create a new dataset with those transformations in-place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5j9yFuaS8PCQ"
   },
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xBx6FdG-8PCT"
   },
   "outputs": [],
   "source": [
    "mnist_transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZQSYv2RT8PCV"
   },
   "outputs": [],
   "source": [
    "mnist_train = datasets.MNIST(data_dir, download=True, train=True, transform=mnist_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gfHktCJM8PCX"
   },
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=num_cpus//1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iv9xA0vu8PCZ"
   },
   "source": [
    "Let's also create a validation set from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R-kHrp-S8PCa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: data\n",
      "    Split: Test\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# LOAD THE MNIST TEST SET AS VALIDATION SET\n",
    "#if train is set to False, it creates a dataset from test.pt\n",
    "mnist_val = datasets.MNIST(data_dir, download=True, train=False)\n",
    "\n",
    "print(mnist_val)\n",
    "print(len(mnist_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7x2bflgq8PCc"
   },
   "outputs": [],
   "source": [
    "# CREATE A VALIDATION DATA LOADER\n",
    "#first transform the dataset as the train dataset before\n",
    "mnist_val = datasets.MNIST(data_dir, download=True, train=True, transform=mnist_transforms)\n",
    "val_dataloader = torch.utils.data.DataLoader(mnist_val, batch_size=batch_size, shuffle=True, num_workers=num_cpus//1)\n",
    "#take the same batchsize as before, but change the used dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mwajdHCS8PCf"
   },
   "source": [
    "Let's get a data point now to see what we're dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9bJyeTET8PCf",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           ...,\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
       " \n",
       " \n",
       "         [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           ...,\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
       " \n",
       " \n",
       "         [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           ...,\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           ...,\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
       " \n",
       " \n",
       "         [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           ...,\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
       " \n",
       " \n",
       "         [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           ...,\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "           [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]]]),\n",
       " tensor([5, 5, 3, 1, 1, 7, 3, 2, 1, 0, 1, 6, 3, 1, 7, 3, 2, 6, 1, 0, 7, 7, 7, 0,\n",
       "         1, 3, 4, 2, 3, 8, 1, 8, 7, 3, 8, 5, 6, 5, 3, 3, 2, 7, 3, 9, 6, 1, 0, 0,\n",
       "         0, 6, 6, 6, 7, 0, 2, 4, 4, 5, 6, 6, 5, 1, 4, 1, 1, 1, 0, 6, 2, 7, 0, 8,\n",
       "         2, 8, 3, 7, 7, 7, 3, 5, 9, 3, 3, 8, 9, 8, 4, 6, 6, 8, 4, 1, 2, 1, 6, 1,\n",
       "         9, 5, 8, 8, 6, 7, 9, 9, 3, 3, 6, 6, 2, 1, 0, 2, 5, 1, 2, 2, 7, 6, 2, 9,\n",
       "         2, 5, 6, 3, 6, 3, 8, 6, 1, 4, 5, 4, 4, 0, 7, 9, 8, 8, 2, 7, 4, 1, 4, 2,\n",
       "         7, 0, 4, 5, 2, 0, 7, 4, 9, 2, 0, 0, 5, 1, 2, 7, 6, 5, 1, 6, 5, 9, 5, 6,\n",
       "         5, 7, 2, 7, 1, 1, 5, 5, 2, 1, 1, 3, 2, 9, 8, 1, 4, 8, 7, 6, 8, 9, 3, 0,\n",
       "         3, 5, 0, 2, 6, 6, 1, 2, 7, 1, 9, 7, 3, 8, 0, 5, 5, 5, 7, 7, 9, 0, 0, 2,\n",
       "         0, 4, 4, 0, 9, 7, 7, 3, 4, 3, 0, 7, 6, 6, 4, 4, 9, 6, 0, 0, 0, 6, 9, 3,\n",
       "         7, 3, 7, 3, 3, 2, 4, 4, 2, 1, 0, 5, 6, 7, 6, 5]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(train_dataloader))\n",
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pPujqFJJ8PCh"
   },
   "source": [
    "If you you're wondering about that ``next(iter(.))``-business check out how python's iterator protocol works. It's simple and will give you an important insight into python: https://wiki.python.org/moin/Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xnsc8PHk8PCi"
   },
   "source": [
    "***QUESTION 1:*** How does the element access above work? What do the functions do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ewxt58dA8PCj"
   },
   "source": [
    "***SOLUTION:*** \n",
    "\n",
    "Iter is only defined for an iterable object, that means that _iter_ is defined for the object. If next is implemented as well, it is possible to get the next element of the object until there are no more elements avaible. \n",
    "In the easiest case itter will return it self or if there is only one element. \n",
    "\n",
    "In more the less a loop, it calls next until it reaches \"StopIteration\", so there are no more elements are avaible and the 'loop' ends. In this case the number of batches defines the number of iterations.\n",
    "\n",
    "we set: batch_size = 256\n",
    "and we get: len(x) = len(y) = 256\n",
    "\n",
    "It is also possible to use it in 'for-loops', so to construct with result a loop again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aCOFaXdY8PCj"
   },
   "source": [
    "The data loader gives us two tensors. The first is a tensor with dimensons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i8Qvblsw8PCk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 1, 28, 28])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape\n",
    "#shape returns in this case the size of an torch object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MaCZs36H8PCm"
   },
   "source": [
    "and the second has dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QeAHSJBh8PCn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mtxIKF3i8PCp"
   },
   "source": [
    "(``.shape`` and ``.size()`` are both valid and used interchangably throughout pytorch.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-e4iRr3a8PCq"
   },
   "source": [
    "x has size (4, 1, 28, 28) --> 4 batches (or whatever you have defined in your data loader), 1 channel (the images are monochrome), 28 height/rows, 28 width/cols."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ovQSOElc8PCq"
   },
   "source": [
    "y has size (4) --> 4 batches (again depends on your data loader config). There's one label for each of the images in the batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CJuJ01YK8PCr"
   },
   "source": [
    "How about the mean of a couple of batches? Should be approx. 0. Extra exercise compute the std. dev. as well.\n",
    "Let's create a new data loader first, that will load only a subset of the data. A data loader that loadds only a subset is often great to iterate quickly through experiments/parameters early on in the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fq-oLpf68PCr"
   },
   "source": [
    "***QUESTION 2:*** To get a datloader that operates on a subset of a given data set, you can provide the data loader with a custom sampler. For this exercise define a sampler that will load random samples from a subset of the data set. The PyTorch docs are your friend!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "py3oti6J8PCs"
   },
   "source": [
    "***SOLUTION:*** TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k1eBsrV78PCs"
   },
   "outputs": [],
   "source": [
    "# DEFINE A SAMPLER THAT WILL LOAD RANDOM SAMPLES FROM A SUBSET OF THE DATASET\n",
    "sampler = torch.utils.data.RandomSampler(mnist_train) #or: \n",
    "#sampler =torch.utils.data.RandomSampler(mnist_train, replacement=True, num_samples=5)\n",
    "#https://pytorch.org/docs/stable/data.html#torch.utils.data.RandomSampler\n",
    "#if a sampler is used, shuffle has to be False! (standard)\n",
    "subset_loader = torch.utils.data.DataLoader(mnist_train, batch_size=4, num_workers=num_cpus//1, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WHrMytEm8PCt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0001)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = [x.mean() for x, _ in subset_loader]\n",
    "torch.stack(means).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RGt_nBBU8PCw"
   },
   "source": [
    "## Create a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VYwmFD708PCx"
   },
   "source": [
    "Now we're going to define the model that we're going to train on the data. Let's go for a simple, fully connected network also called multi-layer perceptron (MLP). An MLP consists of multiple fully connected layers with activation functions in between. In pytorch a fully connected layer is called *linear* layer. We'll use a sigmoid as activation functions within the network and a softamx for the categorical output.\n",
    "\n",
    "Nets are defined as composable modules. Typically one would implement the initialization and the forward function. ``__init__`` usually instantiates sub-modules, while forward uses those modules to compute the forward function. The backward pass is performed automatically with autograd, which is the core feature of pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Vz7JxSw8PCy"
   },
   "source": [
    "### Define the archtiecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h33UL8xx8PC0"
   },
   "source": [
    "Now we need to define a net to train on our data. Let's use a simple MLP with three linear layers and some activation function (ReLU, LeakyReLU, Sigmoid, tanh?). The second layer should have the same amount of inputs as the initial layer. The last layer should have half as many inputs as the middle layer. \n",
    "\n",
    "Look up ``nn.Linear`` in the PyTorch docs. What should the input size be? How many elements are in the input data?\n",
    "\n",
    "Also lookup potential activation functions.\n",
    "\n",
    "In the forward function first \"flatten\" the input vector. The input vector will be of size (BATCH_SIZE, 28, 28). However, the linear layers only take data of size (BATCH_SIZE, N). So, you need to flatten the last two dimensions. There's a vector operation for this purpose in PyTorch. Then run the input data through all your layers in the proper sequence.\n",
    "\n",
    "In general in PyTorch most operations happen on (BATCH_SIZE, ...) because batches are computed in parallel on GPUs. So most of the time the BATCH_SIZE is there implicitly in operations and tensors.\n",
    "\n",
    "Hint for the output layer: you need to have an output of size (BATCH_SIZE, 10) for our loss function to work. Again, the batch size is implicit in the definition of the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "msbzlVSI8PC1"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_layers=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = [nn.Linear(a,a),  # <DEFINE INPUT ANd OUTPUT FOR THE LINEAR LAYER>),\n",
    "                  nn.Linear(a,b),  #a und b sind nur Platzhalter, mit b=a/2 siehe Aufgabe, 10 da wir 10 Zahlen haben\n",
    "                  nn.Linear(b,10)] #und output des vorherigen muss gleich input des nÃ¤chsten sein!\n",
    "        # DEFINE ACTIVATION FUNCTIONS AND MORE LAYERS\n",
    "        self.lls = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        #x = x.flatten() #\n",
    "        # <FLATTEN THE INPUT TO A SUITABLE SIZE FOR THE INITIAL LINEAR LAYER>\n",
    "        # <RUN THE DATA THROUGH ALL OF YOUR LAYERS>\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_layers=1):\n",
    "        super().__init__()\n",
    "        #three layers in my neural network\n",
    "        self.input_layer = nn.Linear(784,784) \n",
    "        self.hidden_layer = nn.Linear(784,392)\n",
    "        self.output_layer =nn.Linear(392,10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0] #get the batch-size\n",
    "        res = [] #to store the results\n",
    "        for i in range(batch_size): #to loop the function over all batches\n",
    "            x_i = x[i] #x_i is the actuall input we look at\n",
    "            x_i = x_i.flatten() #flatten the input\n",
    "            x_i = F.relu(self.input_layer(x_i)) #apply the activation-fct to the input-layer\n",
    "            x_i = F.relu(self.hidden_layer(x_i)) \n",
    "            x_i = F.softmax(self.output_layer(x_i)) #applay the softmax to the output_layer to generate the output\n",
    "            res.append(x_i)\n",
    "        return res\n",
    "        \n",
    "    \n",
    "\n",
    "#model = MLP()\n",
    "#model = model(x)\n",
    "#print(mod)\n",
    "k = 0\n",
    "#print(mod(x)) #prediction: 8 or 7- highest prob, depends on how they count\n",
    "#print(max(mod(x)))\n",
    "#print(y[k]) #result: 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zAETgRHt8PC3"
   },
   "source": [
    "### Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tmCKjfEk8PC3"
   },
   "outputs": [],
   "source": [
    "model = MLP(num_layers=1).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2cATXj3w8PC5"
   },
   "source": [
    "Let's take a look a look at the inside of our model. It's always a good idea to verify that the actual architecture is what you intended it to be. Especially, when you start to create layers dynamically it's great for inspection/verification/debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FWku4YJN8PC5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (input_layer): Linear(in_features=784, out_features=784, bias=True)\n",
       "  (hidden_layer): Linear(in_features=784, out_features=392, bias=True)\n",
       "  (output_layer): Linear(in_features=392, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Bcnh2pX8PC7"
   },
   "source": [
    "## Define a loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wsBp_tRW8PC8"
   },
   "source": [
    "So far we've avoided to define the final layer activation in our net. Since we're deadling with multi-class classification (i.e. multiple categories), softmax is the canonical choice for the final layer activation. Softmax provides us with a distribution of values $\\in [0, 1]$ that sum to 1 over all categories.\n",
    "\n",
    "The softmax function typically goes hand-in-hand with negative log-likelihood (NLL) as loss function. So, naively, one would set the final layer activation to softmax and then the loss to NLL. However, NLL expects log-probablities, but softmax provides probabilities. Thus, we would need to compute the log of softmax's output. This approach in turn leads to numerical instabilities, which in turn make it harder for your net to converge. One solution is to use ``LogSoftmax``, which computes the log probabilities from the softmax direclty. It's numerically stable and faster, than the manual approach. An alternative, but functionally equivalent, approach is to skip the final layer activation and to use ``nn.functional.cross_entropy``. This is a loss function that combines ``LogSoftmax`` and ``NLLLoss`` . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "io-oTx5G8PC9"
   },
   "outputs": [],
   "source": [
    "loss_fn = F.cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RXFxILek8PC_"
   },
   "source": [
    "## Define the optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sxDcXQN18PC_"
   },
   "source": [
    "Let's use Adam as optimizer, since it's robust and thus easy to use. We need to pass the model parameters to the optimizer, because the optimizer needs to adjust thos based on the accumulated gradients after backprop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mx4pwiPO8PDA"
   },
   "source": [
    "Look up how to set the learning rate with Adam and **initialize the optimizer below with a learning rate of 1e-4**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ml3kRzmR8PDA"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), betas=(0.9, 0.999)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1omb8VDi8PDB"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XU2XIM858PDC"
   },
   "outputs": [],
   "source": [
    "train_loss, val_loss = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XVqrabMZ8PDD"
   },
   "source": [
    "Let's define the inner training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zdBGUcyO8PDD"
   },
   "outputs": [],
   "source": [
    "def accuracy(correct, total): return float(correct)/total\n",
    "    \n",
    "def train(dataloader, optimizer, model, loss_fn, train_loss, device, master_bar):\n",
    "    epoch_loss = []\n",
    "    epoch_correct = 0\n",
    "    epoch_total = 0\n",
    "    # <LOOP OVER THE DATA LOADER AND USE fastprogress.progress_bar WITH master_bar FOR OUTPUT>\n",
    "    for x, y in fastprogress.progress_bar(dataloader, parent=master_bar):\n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "        y_pred = model(x.to(device))\n",
    "        hits = y == y_pred.argmax(dim=1)\n",
    "        epoch_correct += sum(hits)\n",
    "        epoch_total += len(hits)\n",
    "        loss = loss_fn(y_pred, y.to(device))# <MOVE THE LABEL TO YOUR DEVICE AND COMPUTE THE LOSS>\n",
    "        gradients = loss.backward() ## <COMPUTE THE GRADIENTS IN A BACKWARD PASS>\n",
    "        optimizer.step(gradients) ## <USE THE COMPUTED GRADIENTS TO PERFORM AN OPTIMIZATION STEP> optimizer.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "        averaged_loss = sum(epoch_loss[-50:])/len(epoch_loss[-50:])\n",
    "        master_bar.child.comment = f'Train loss: {averaged_loss:.2f}, train accuracy: {accuracy(epoch_correct, epoch_total):.3f}'\n",
    "    train_loss.extend(epoch_loss)\n",
    "    epoch_accuracy = accuracy(epoch_correct, epoch_total)\n",
    "    return epoch_loss, epoch_accuracy\n",
    "\n",
    "def validate(dataloader, model, loss_fn, val_loss, device, master_bar):\n",
    "    # XXX Using a plain list and appending to it can a) be slow b) lead to memory leaks!\n",
    "    # Use something like a ring buffer for things you want to re-use here in code and\n",
    "    # tensorboardx for training metrics in larger setups.\n",
    "    epoch_loss = []\n",
    "    confusion = torch.zeros(10, 10)\n",
    "    epoch_correct = 0\n",
    "    epoch_total = 0\n",
    "    epoch_misclassified = []\n",
    "    confusion = torch.zeros(10, 10, dtype=torch.int32)\n",
    "    for x, y in fastprogress.progress_bar(dataloader, parent=master_bar):\n",
    "        model.eval()\n",
    "        y_pred = model(x.to(device))\n",
    "        y_pred_idxs = y_pred.argmax(dim=1)\n",
    "        for (idx_true, idx_pred) in zip(y, y_pred_idxs):\n",
    "            confusion[idx_true, idx_pred] += 1\n",
    "        hits = y == y_pred_idxs\n",
    "        epoch_correct += sum(hits)\n",
    "        epoch_total += len(hits)\n",
    "        misclassified = list(zip([x for x in x[~hits]], y[~hits]))\n",
    "        epoch_misclassified.extend(misclassified)\n",
    "        loss = loss_fn(y_pred, y.to(device))\n",
    "        epoch_loss.append(loss.item())\n",
    "        averaged_loss = sum(epoch_loss[-50:])/len(epoch_loss[-50:])\n",
    "        master_bar.child.comment = f'Val loss: {averaged_loss:.2f}, train accuracy: {accuracy(epoch_correct, epoch_total):.3f}'\n",
    "    epoch_accuracy = accuracy(epoch_correct, epoch_total)\n",
    "    return epoch_loss, epoch_accuracy, epoch_misclassified, confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xEsabo1Y8PDE"
   },
   "source": [
    "***Question 3:*** Why are we using `optimizer.zero_grad()` in the training loop for each batch? Why aren't we doing that in the validation loop as well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oZMk2tNK8PDF"
   },
   "source": [
    "***SOLUTION:*** \n",
    "\n",
    "1. Observe how gradient buffers had to be manually set to zero using optimizer.zero_grad(). This is because gradients are accumulated and need to clear it, because otherwise we will accumulate it to existing gradients.\n",
    "\n",
    "2. We do not need in the validation loop, because there we do not want to train our model anymore. We also want to keep the history and accumlate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T6pTA-CF8PDF"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'fastprogress' has no attribute 'master_bar'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-134-270b4d6f3e31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmaster_bar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfastprogress\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaster_bar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmaster_bar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mepoch_train_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_train_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaster_bar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'fastprogress' has no attribute 'master_bar'"
     ]
    }
   ],
   "source": [
    "#error while running: AttributeError: module 'fastprogress' has no attribute 'master_bar'\n",
    "\n",
    "num_epochs = 3\n",
    "master_bar = fastprogress.master_bar(range(num_epochs))\n",
    "for epoch in master_bar:\n",
    "    epoch_train_loss, epoch_train_acc = train(train_dataloader, optimizer, model, loss_fn, train_loss, device, master_bar)\n",
    "    epoch_train_mean_loss = sum(epoch_train_loss)/len(epoch_train_loss)\n",
    "    epoch_val_loss, epoch_val_acc, misclassified, confusion = validate(val_dataloader, model, loss_fn, val_loss, device, master_bar)\n",
    "    epoch_val_mean_loss = sum(epoch_val_loss)/len(epoch_val_loss)\n",
    "    master_bar.write(f'Train loss: {epoch_train_mean_loss:.2f}, val loss: {epoch_val_mean_loss:.2f}, train acc: {epoch_train_acc:.3f}, val acc {epoch_val_acc:.3f}')\n",
    "    master_bar.update_graph([[range(len(epoch_train_loss)), epoch_train_loss]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JiWqnkwZ8PDH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23a8cf50908>]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GzuyqkFr8PDJ"
   },
   "source": [
    "Let's take a look at random misclassified images. Misclassified images can give you a better feeling for well your classifier is doing and where it's weaknesses may lie. Are the misclassified images really hard to interpret? Are there any obvious patterns that the classifier doesn't get? Would you do better yourself?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rw1KlNK78PDK"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'misclassified' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-123-128bde257e67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmisclassified\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'misclassified' is not defined"
     ]
    }
   ],
   "source": [
    "len(misclassified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-Rqs9ZZ8PDL"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'misclassified' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-124-f020066320ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrand_miss_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmisclassified\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mrand_miss_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrand_miss_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.1307\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m0.3081\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m0.3081\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mrand_miss_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pil_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrand_miss_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mrand_miss_image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'misclassified' is not defined"
     ]
    }
   ],
   "source": [
    "rand_miss_tensor, label = random.choice(misclassified)\n",
    "rand_miss_tensor = TF.normalize(rand_miss_tensor, (-0.1307/0.3081,), (1/0.3081,))\n",
    "rand_miss_image = TF.to_pil_image(rand_miss_tensor)\n",
    "print(label)\n",
    "rand_miss_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hdo-bre38PDN"
   },
   "source": [
    "Let's take a look at the confusion matrix to get a feeling for the most misclassified numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C0W4q-RL8PDO"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-be90ac10e373>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'confusion' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sn.heatmap(confusion, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9hrkgCMq8PDP"
   },
   "source": [
    "**Exercise** Where do you see most misclassifications in the confusion matrix above? Which classes are misclassified in what way?\n",
    "\n",
    "Problem, I can not se the figure/ confusion matrix. I do not know if my model is specified correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_2h8ZfbH8PDP"
   },
   "source": [
    "Let's continue to train and see what happens. Btw. you can interrupt the execution by pressing `i` twice or with the \"stop\" button in the menu in Jupyter. In Colab press `Cmd/Ctrl+M` I or use the \"Runtime\" menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kkHoMNn78PDQ",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'fastprogress' has no attribute 'master_bar'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-126-f30124dc6310>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmaster_bar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfastprogress\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaster_bar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmaster_bar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mepoch_train_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_train_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaster_bar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mepoch_train_mean_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_train_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_train_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'fastprogress' has no attribute 'master_bar'"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "master_bar = fastprogress.master_bar(range(num_epochs))\n",
    "for epoch in master_bar:\n",
    "    epoch_train_loss, epoch_train_acc = train(train_dataloader, optimizer, model, loss_fn, train_loss, device, master_bar)\n",
    "    epoch_train_mean_loss = sum(epoch_train_loss)/len(epoch_train_loss)\n",
    "    epoch_val_loss, epoch_val_acc, misclassified, confusion = validate(val_dataloader, model, loss_fn, val_loss, device, master_bar)\n",
    "    epoch_val_mean_loss = sum(epoch_val_loss)/len(epoch_val_loss)\n",
    "    master_bar.write(f'Train loss: {epoch_train_mean_loss:.2f}, val loss: {epoch_val_mean_loss:.2f}, train acc: {epoch_train_acc:.3f}, val acc {epoch_val_acc:.3f}')\n",
    "    master_bar.update_graph([[range(len(epoch_train_loss)), epoch_train_loss]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W6VXzDdU8PDT"
   },
   "source": [
    "***QUESTION 4:*** What is you observation regarding the relation of the training metrics to the validation metrics? What does you observation hint at?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YafzwPYI8PDU"
   },
   "source": [
    "***SOLUTION:*** not possible to answer, is not working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wdr8vpc28PDW"
   },
   "source": [
    "***QUESTION 5:*** Modify the initialization of our optimizer to apply L2 weight decay for regularization. Try a value of 0.001 and then experiment a little. How does L2 regularization impact the results? Copy the necessary cells from above below this cell and modify the code as needed. Which value for L2 regularization did you find to work well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jc-giVU48PDW"
   },
   "source": [
    "***SOLUTION:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L1oyf-OU8PDX"
   },
   "outputs": [],
   "source": [
    "# TODO copy cells from above and apply L2 regularization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EYDuItzf8PDY"
   },
   "source": [
    "***QUESTION 6:*** Instead of L2 regularization now use dropout. Add dropout layers after the activations in your network definition. Start with a drop out probability of 0.5 and then experiment with the parameter until you get satisfactory results. Again, copy only the required code from above, run it again and evaluate the results. Which *value* for dropout did you find to work well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EbALuirp8PDY"
   },
   "source": [
    "***SOLUTION:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kE9Px12r8PDZ"
   },
   "outputs": [],
   "source": [
    "# TODO copy cells from above and apply dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gk8kyYwf4IqS"
   },
   "source": [
    "***QUESTION 7:*** Can you explain what the line `model.eval()` at the beginning of the validation loop in the function `validate()` defined above does and why it is necessary to include it when using dropout regularization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x2uYFluS5N82"
   },
   "source": [
    "***SOLUTION:*** TODO"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "RSaZHscD8PBK",
    "o_TiepIM8PBP",
    "43pXTPMg8PBV"
   ],
   "name": "DeepLearning19_Homework2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
